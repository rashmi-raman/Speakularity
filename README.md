Implementing Speakularity 
Can we use/tweak/interface some existing systems or develop components using
algorithms with respectable accuracy to build a robust, easy-to-use transcribing system for reporters.

The capabilities of the system would include :

1. Convert the audio component of the interview to text using a good quality, inexpensive automatic speech recognizer
2. Extract entities from the audio so as to identify the speakers
3. While converting, also provide context : time/location data, include slugs, speakers taking turns, information about the speaker (topic pages?) etc.
4. Provide an interface for journalists to correct the transcription - while hearing the audio/viewing to the video
5. Extracting some information about the source / interviewee to store in a database (which could then be used as a lookup source for future transcripts)
6. Provide a structured method to store these files so that they are easily searchable and index able

Starting off with an  initial paper on whether existing open source Automatic Speech Recognition systems and Named Entity Recognizers can be used to build Speakularity.